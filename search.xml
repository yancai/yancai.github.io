<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[tutorial-pip]]></title>
    <url>%2Fdoc%2Fpython%2Ftutorial-pip%2F</url>
    <content type="text"><![CDATA[简介本文将介绍： Python包是什么？ 如何安装Python包？ 以及Python的常用包管理工具pip(Package Installer for Python)的常用方法和配置方式。 Python包在常见的语言中，都会将一个或一组功能封装好，以包的形式发布复用。比如：Java使用maven构建jar包、war包；Node.js使用npm安装管理包。 Python中也有包这一概念。Python包的格式也是经历了几代的进步，最早有.egg包（Python是大蟒，egg是蛋，那么Python的包就叫做egg），后来有.whl包，直到如今很多包使用.zip、.tar.gz。如今的Python包已经越来越好用了。 Python包安装方法Python包如何安装呢？以下将介绍一下Python包的手动安装方式。 安装Python包，绝大多数情况下建议使用本文后半部分的pip方式安装，只在万不得已的情况下使用手动安装。例如：只有安装包，而没有网络时候。 以下将介绍如何手动安装Python中一个大名鼎鼎的包——requests，其它包的安装方式类似，request包下载地址如下：https://files.pythonhosted.org/packages/52/2c/514e4ac25da2b08ca5a464c50463682126385c4272c18193876e91f4bc38/requests-2.21.0.tar.gz 下载好包之后，在任意目录解压开，可以看到如下的目录结构： 1234567891011121314`-- requests-2.21.0 |-- HISTORY.md |-- LICENSE |-- MANIFEST.in |-- Pipfile |-- Pipfile.lock |-- PKG-INFO |-- pytest.ini |-- README.md |-- requests |-- requests.egg-info |-- setup.cfg |-- setup.py `-- tests 其中setup.py是一个很关键的文件 在setup.py同级目录中使用如下命令即可安装requests包 1python setup.py install 注意： 务必在setup.py同级目录中执行如上命令，否则会有可能导致安装失败 安装时打印的日志如果没有异常，那么安装就顺利完成啦 不同平台由于用户权限的问题，在执行python setup.py install时，可能需要root权限，在最前面加sudo，即sudo python setup.py install 由于Python包之间可能存在依赖关系，安装A包时候如果依赖了B包，但是B包如果没有安装，那么A包会安装失败，所以还是建议使用更高级的pip来进行包管理 pip是神马？PyPI是神马？ pip is the package installer for Python. You can use pip to install packages from the Python Package Index and other indexes. 以上这段是pip官方的一段话，解释了pip和PyPI是什么，以及两者之间的关系。 简单的来讲，pip（Package Installer for Python）就是Python的安装工具。使用pip可以从PyPI（Python Package Index）官方索引下载并安装Python包，或者从其他镜像源下载。 使用pip安装Python包的时候，可以解决包依赖之间的问题，也可以一次下载安装多个Python包，目前pip已经是Python官方所支持的包安装工具。在某些环境（例如Windows）上安装Python时，已经自带pip工具。 常用的PyPI镜像如下： PyPI官方：https://pypi.org/ 阿里PyPI镜像源：https://mirrors.aliyun.com/pypi/simple/ 网易PyPI镜像源：http://mirrors.163.com/pypi/simple/ 豆瓣PyPI镜像源：https://pypi.doubanio.com/simple/ pip的安装方法Windows系统安装pipWindows上安装包目前已经自带了pip，安装时勾选pip即可。 Ubuntu系统安装pipUbuntu上通常并没有自带pip，使用apt即可安装pip，命令如下： 12345# 安装Python3对应的pipsudo apt install python3-pip# 安装Python2对应的pipsudo apt install python-pip CentOS系统安装pip通常yum的官方仓库中木有pip，呵呵so~参考下面的通用安装pip方法 通用安装pip方法由于各平台包管理工具对于pip支持不尽相同，因此有时候不得不使用手动方式安装pip，手动安装方式在Windows、CentOS、Ubuntu、Mac等系统上均适用。 下载安装包 从PyPI搜索并下载https://pypi.org/，下载时候如果没有特殊要求，那就直接下载最新的稳定版本； 或者从点击如下超链接直接下载： pip-19.0.3.tar.gz 安装pip 12345678# 解压pip包tar -xvf pip-19.0.3.tar.gz# 进入目录cd pip-19.0.3# 安装pippython setup.py install 注意： 不同平台上由于Python环境不同，可能有些环境上安装pip时会报缺少setuptools，例如： 1234Traceback (most recent call last):File &quot;setup.py&quot;, line 6, in &lt;module&gt; from setuptools import find_packages, setupImportError: No module named setuptools 在这种情况下，需要先手动安装setuptools，可以从PyPI搜索下载，或点击此处setuptools-40.8.0.zip下载安装包。 pip的常用操作 搜索包 12# 搜索 名称为xxx 的包pip search xxx 示例：搜索名为request的包 123456$ pip search requestsrequests-hawk (1.0.0) - requests-hawkrequests-dump (0.1.3) - `requests-dump` provides hook functions for requests....requests (2.21.0) - Python HTTP for Humans.... 安装包 12# 安装 名称为xxx 的包pip install xxx 示例 1234567891011# 安装 名称为requests 的包pip install requests# 安装 名称为requests，版本为2.21.0 的包pip install requests==2.21.0# 安装 名称为requests，版本号小于等于2.20 的包pip install 'requests&lt;=2.20'# 安装 名称为requests，版本号大于等于2.10且小于2.15 的包pip install 'requests&gt;=2.10,&lt;2.15' 卸载包 12# 卸载 名称为xxx 的包pip uninstall xxx 示例 12# 卸载 名称为requests 的包pip uninstall requests 列出当前环境已安装的Python包 123456789$ pip listPackage Version--------------------- ----------pip 18.0pipenv 2018.11.26requests 2.21.0setuptools 39.0.1virtualenv 16.0.0... pip镜像配置使用pip安装包时，默认会从PyPI官方下载包。由于网络的原因，通常会下载比较慢或者无法下载。为了解决这个问题，可以修改默认的pip下载镜像源，改为速度较快的镜像源。 以下示例为修改pip镜像源为阿里巴巴开源镜像站的PyPI镜像源（若使用其它镜像源，配置方法类似）： 在Linux系统或Mac系统创建文件：~/.pip/pip.conf 在Windows系统创建文件：%USERPROFILE%\pip\pip.ini 具体文件内容如下： 12345[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.com 按照如上配置后，再使用pip安装包时，就会从指定的镜像源下载包了，然后就可以开始愉快的玩耍啦~]]></content>
      <tags>
        <tag>Python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用rancher部署kubernetes介绍]]></title>
    <url>%2Fdoc%2Fdocker%2Francher-k8s-deploy%2F</url>
    <content type="text"><![CDATA[简介本文将介绍在VMware虚拟环境下使用Rancher部署Kubernetes 依赖版本 docker: 17.03.3-ce rancher: v1.6.21 kubernetes: v1.10.5 helm: v2.8.2 包含Docker的VMware虚拟环境创建 虚拟机创建新建一个Linux的虚拟环境vm01，建议为CentOS7.x或Ubuntu18.04 安装docker 安装参考: https://docs.docker.com/install/ 安装好后设置镜像和dnssudo vim /etc/docker/daemon.json 12345678910&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ], "dns":[ "114.114.114.114", "8.8.8.8", "8.8.4.4" ]&#125; 创建快照基于vm01快照创建新的虚拟机vm02在vm02中修改：ubuntu sudo vim /etc/cloud/cloud.cfg: 设置preserve_hostname: true 修改hostname和hosts hostname 作用 vm01 部署rancher vm02 部署kubernetes Rancher部署vm01上部署Rancher 安装Rancher使用docker-compose拉起Rancher，docker-compose使用方法参见：《使用docker-compose编排容器快速上手指南》 docker-compose.yaml如下 1234567891011version: '2.2'services: rancher: image: rancher/server:v1.6.21 container_name: rancher hostname: rancher environment: - TZ=Asia/Shanghai ports: - 8080:8080 restart: always 配置Rancher主机访问http://vm01:8080 添加主机 Rancher API地址确认 添加主机，将生成的脚本复制并在Rancher的主机vm01上执行 稍等片刻，rancher会自动下载相关的镜像并拉起容器 部署Kubernetesvm02上部署kubernetes 添加Kubernetes环境【环境管理】-【添加环境】-选择Kubernetes 获取添加kubernetes脚本切换至kubernetes环境页面 添加主机，将生成的脚本复制并在Kubernetes的主机vm02上执行 执行后稍等片刻 完成后可以查看主机上的信息 配置kubectl 1234# 安装kubectlcurl -LO https://storage.googleapis.com/kubernetes-release/release/v1.10.5/bin/linux/amd64/kubectlsudo mv ./kubectl /usr/local/bin/kubectlsudo chmod +x /usr/local/bin/kubectl 将kubectl配置写入vm02的~/.kube/config中 部署helm配置了kubectl配置文件的vm02上安装helm客户端 安装helm 1234wget https://storage.googleapis.com/kubernetes-helm/helm-v2.8.2-linux-amd64.tar.gztar -xvf helm-v2.8.2-linux-amd64.tar.gzsudo mv linux-amd64/helm /usr/local/bin/helmsudo chmod +x /usr/local/bin/helm 初始化helm 1helm init]]></content>
      <tags>
        <tag>Rancher</tag>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go开发环境配置]]></title>
    <url>%2Fdoc%2Fgo%2Fgo-env%2F</url>
    <content type="text"><![CDATA[简介本文介绍Go开发环境的配置方法 SDK 安装 安装包下载下载地址：https://golang.org/dl/下载Windows、Linux或Mac平台下的安装包 安装SDKLinux, Mac上执行 12# 注意修改包名tar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gz Windows上执行exe进行安装 配置环境变量Linux, Mac 1234export GOHOME=/usr/local/goexport PATH=$PATH:$GOHOME/binexport GOPATH=$HOME/goexport PATH=$PATH:$GOPATH/bin Windows新建环境变量GOHOME，值为Go安装位置新建环境变量GOPATH，设置并创建一个路径，例如：D:\AppData\goPATH中追加：;%GOHOME%\bin;%GOPATH%\bin; 验证命令行中输入go version可以正常查看go版本信息 GoLand 下载GoLand安装包下载地址：https://www.jetbrains.com/go/download/ 安装GoLand执行安装包，根据提示安装 下载go工程可以下载我的示例工程： 1go get github.com/yancai/hello-go 下载好后，所在位置为$GOPATH/src/github.com/yancai/hello-go 命令行构建运行 12345678910# 命令行中执行go build github.com/yancai/hello-go# 在命令行当前目录中会生成 可执行文件hello-go 或 hello-go.exe# Linux, Mac执行如下./hello-go# Windows执行如下hello-go.exe# 输出：# Hello go! 使用GoLand开发【Open Project】 -&gt; 选择工程目录$GOPATH/src/github.com/yancai/hello-go，打开工程目录即可完成工程导入开发Debug方式和JetBrains其他产品（IDEA、PyCharm）类似 其它 开发过程中，如需下载第三方包，执行如下命令1go get xxx]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[发布你的个人docker镜像]]></title>
    <url>%2Fdoc%2Fdocker%2Fpublish-your-image%2F</url>
    <content type="text"><![CDATA[简介 假如你有一个比较好的docker镜像怎么发布出来供大家使用呢？ 你是否遇到过国外某些镜像很难下载下来呢？ 你是否想过拥有一个自己的镜像仓库呢？ 本文将介绍如何使用Docker Hub和阿里云的容器镜像服务来创建自己的docker镜像仓库 Dockerfile以下为本文构建镜像时所使用的Dockerfile12FROM k8s.gcr.io/etcd-amd64:3.1.12MAINTAINER yancai yancai915@gamil.com 文件托管于https://github.com/yancai/myDockerfiles/blob/master/kubernetes/etcd-amd64/Dockerfile Docker Hub 打开https://hub.docker.com 注册一个Docker Hub用户，并登录 绑定GitHub账号点击【Setting】 - 【Linked Accounts &amp; Service】绑定Github账号 选择Public and Private 跳转至GitHub页面，授权即可 授权后可以看到已经绑定成功 创建构建计划点击【Create】-【Create Automated Build】，选择GitHub 选择Dockerfile所在的仓库 填写镜像名称和介绍信息后点击【Create】 设置构建计划选择【Type】，选择Branch或Tag填写【Name】，填写Branch或Tag的名称填写【Dockerfile Location】，此路径为相对于GitHub仓库代码根目录的Dockerfile所在的路径填写【Docker Tag Name】，版本信息完成后点击【Save Changes】保存 触发构建首次保存构建信息后，如需开始构建需要手动点击【Trigger】触发构建。稍等片刻即可完成构建。之后在GitHub上修改了相关代码提交后会自动触发Docker Hub构建。 下载镜像构建完成后可以根据【Repo Info】和【Tags】中的镜像信息下载镜像，例如本示例下载方式为： 1sudo docker pull yancai/demo-image:3.1.12 Docker Hub提供的镜像构建服务挺好用的，唯一就是构建好之后下载镜像时候，由于网络原因可能会十分慢。可以借用国内的一些类似Docker Hub的镜像服务来进行镜像构建和下载。以下将介绍如何在阿里云容器Hub上进行Docker镜像构建和下载。 阿里云 镜像容器服务 打开https://dev.aliyun.com 注册一个阿里云账号，并登录，进入容器镜像服务页面 绑定GitHub账号点击【代码源】-【Github 绑定账号】进行授权绑定代码源 创建镜像仓库点击【镜像仓库】-【创建镜像仓库】选择【地域】选择【命名空间】，如果没有则点击左侧【命名空间】创建命名空间填写【仓库名称】、【摘要】、【描述信息】选择【仓库类型】点击下一步继续 选择GitHub，绑定Dockefile对应的仓库如果有些镜像在国内拉取比较慢或者无法拉取，可以勾选【海外机构建】点击【创建镜像仓库】保存镜像信息 点击对应仓库的【管理】设置构建详情 点击【构建】-【添加规则】选择代码分支或Tag填写【Dockerfile目录】，此路径为相对于GitHub仓库代码根目录的Dockerfile所在的路径填写【Dockerfile文件名】填写【镜像版本】点击【确认】保存 触发构建首次保存构建信息后，如需开始构建需要手动点击【立即构建】触发构建。稍等片刻即可完成构建。如果开启了【代码变更时自动构建镜像】，那么在GitHub上修改了相关代码提交后会自动触发构建。 下载镜像构建完成后根据镜像的【基本信息】、【镜像版本】中的内容可以获取到下载镜像的地址。 例如本示例镜像下载方式为： 1sudo docker pull registry.cn-hangzhou.aliyuncs.com/yancai/demo:3.1.12 使用阿里云下载构建好的镜像，感觉就一个字：快！如此，国外有些镜像难以下载时候，使用阿里云间接拉取构建，下载到本地后重命名镜像名称，这样也就间接的下载了一些无法拉取下来的镜像。]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[minikube 安装介绍]]></title>
    <url>%2Fdoc%2Fdocker%2Fminikube-install%2F</url>
    <content type="text"><![CDATA[简介本文将介绍使用minikube单机部署kubernetes的方法。 版本 minikube:0.28.2 docker:17.03.x-ce 安装指南 安装docker详见https://docs.docker.com/install/ 安装minikube执行命令 1curl -Lo minikube https://github.com/kubernetes/minikube/releases/download/v0.28.2/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo cp minikube /usr/local/bin/ &amp;&amp; rm minikube 下载docker镜像minikube安装过程中会下载docker所需的镜像，需要下载的镜像包含： 123456789101112gcr.io/k8s-minikube/storage-provisioner:v1.8.1k8s.gcr.io/etcd-amd64:3.1.12k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64:1.14.8k8s.gcr.io/k8s-dns-kube-dns-amd64:1.14.8k8s.gcr.io/k8s-dns-sidecar-amd64:1.14.8k8s.gcr.io/kube-addon-manager:v8.6k8s.gcr.io/kube-apiserver-amd64:v1.10.0k8s.gcr.io/kube-controller-manager-amd64:v1.10.0k8s.gcr.io/kube-proxy-amd64:v1.10.0k8s.gcr.io/kube-scheduler-amd64:v1.10.0k8s.gcr.io/kubernetes-dashboard-amd64:v1.8.1k8s.gcr.io/pause-amd64:3.1 由于网络原因以上镜像下载会经常失败，可以从我本人的阿里云镜像仓库中下载，地址为： 123456789101112registry.cn-hangzhou.aliyuncs.com/yancai/storage-provisioner:v1.8.1registry.cn-hangzhou.aliyuncs.com/yancai/etcd-amd64:3.1.12registry.cn-hangzhou.aliyuncs.com/yancai/k8s-dns-dnsmasq-nanny-amd64:1.14.8registry.cn-hangzhou.aliyuncs.com/yancai/k8s-dns-kube-dns-amd64:1.14.8registry.cn-hangzhou.aliyuncs.com/yancai/k8s-dns-sidecar-amd64:1.14.8registry.cn-hangzhou.aliyuncs.com/yancai/kube-addon-manager:v8.6registry.cn-hangzhou.aliyuncs.com/yancai/kube-apiserver-amd64:v1.10.0registry.cn-hangzhou.aliyuncs.com/yancai/kube-controller-manager-amd64:v1.10.0registry.cn-hangzhou.aliyuncs.com/yancai/kube-proxy-amd64:v1.10.0registry.cn-hangzhou.aliyuncs.com/yancai/kube-scheduler-amd64:v1.10.0registry.cn-hangzhou.aliyuncs.com/yancai/kubernetes-dashboard-amd64:v1.8.1registry.cn-hangzhou.aliyuncs.com/yancai/pause-amd64:3.1 从阿里云上下载下来，然后重命名镜像即可。例如：如果要下载镜像k8s.gcr.io/pause-amd64:3.1 123456# 先从对应的阿里云仓库中下载sudo docker pull registry.cn-hangzhou.aliyuncs.com/yancai/pause-amd64:3.1# 添加tagsudo docker tag registry.cn-hangzhou.aliyuncs.com/yancai/pause-amd64:3.1 k8s.gcr.io/pause-amd64:3.1# 删除原有镜像tagsudo docker rmi registry.cn-hangzhou.aliyuncs.com/yancai/pause-amd64:3.1 启动minikube 1sudo minikube start --vm-driver=none 使用dashboard查看kubernetes 12# 此命令可查看dashboard的访问地址，浏览器中打开即可sudo minikube dashboard --url]]></content>
      <tags>
        <tag>kubernetes</tag>
        <tag>minikube</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[好工具集合]]></title>
    <url>%2Fdoc%2Fother%2Fgood-tools%2F</url>
    <content type="text"><![CDATA[介绍“工欲善其事，必先利其器” ——《论语·卫灵公》 好的工具对于日常工作效率提升是很有帮助的，以下为我自己总结的一些很有用的好工具，更多的工具将逐步补充完善。 工具列表目录 介绍 工具列表目录 工具介绍 效率 固态硬盘 Windows原生快速启动 Everything Ditto Snipaste Listary cmder Beyond Compare 文本编辑器 Vim Notepad2 Visual Studio Code Sublime Text Atom Typora 设计 Enterprise Architect Visio 远程工具 OpenSSH MobaXterm PuTTY Xshell 数据库 Robomongo MongoDB Compass DBeaver 工具介绍效率固态硬盘适用系统：Windows | Mac | Linux 非官方介绍：这年头了，还有好多人没有体验过固态硬盘的感觉，赶紧装固态硬盘吧目前市面上主流电脑都应该有固态硬盘，如果没有固态硬盘，用Windows的话，建议买个120~128G的就够用了，分两个盘，80G的盘用来安装系统，其它剩下的40G+用来装常用的软件，用起来相当爽 使用场景：电脑卡卡卡、慢慢慢 Windows原生快速启动适用系统：Windows 配置方法：在%USERPROFILE%\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\建立一个文件夹Tools，常用的快捷方式直接丢到这个文件夹中，也可以把这个文件夹发送到桌面快捷方式方便经常打开使用。 使用方法：需要快速启动应用时，只需按Win键并直接输入快捷方式的名称，系统会自动筛选出对应的应用，然后回车直接打开。 Windows上基本都可以，Win10上体验更好。如此一来就不再安装Launchy、Wox等快速启动工具 使用场景：我的那啥应用在哪？ Everything主页：http://www.voidtools.com/ 适用系统：Windows 官方介绍：Locate files and folders by name instantly.非官方介绍：Windows文件查找利器 使用场景：我的那个啥文件在哪？ Ditto主页：https://ditto-cp.sourceforge.io/ 适用系统：Windows 官方介绍：Clipboard Manager非官方介绍：剪贴板管理好帮手 使用场景：复制过的再复制，啊呀，又要复制下刚才的东西 Snipaste主页：https://www.snipaste.com/ 适用系统：Windows | Mac 官方介绍：Snip &amp; Paste非官方介绍：简单强大的截图工具 使用场景：截图，贴图功能很好用 Listary主页：https://www.listary.com/ 适用系统：Windows 官方介绍：File Search &amp; App Launcher非官方介绍：文件搜索和快速启动 使用场景：搜索文件；快速打开应用；我更喜欢的是使用快速选择文件夹的功能，Windows上传、下载、保存文件时通常要手动选择。使用Listary如果这个文件夹已经打开了，点到对应文件夹，再切回文件选择窗口，这是就已经自动选择到了刚才已经打开的文件夹 cmder主页：http://cmder.net/ 适用系统：Windows 官方介绍：Portable console emulator for Windows非官方介绍：Windows增强命令行工具 使用场景：嫌弃cmd丑丑的界面 Beyond Compare主页：https://www.scootersoftware.com/ 适用系统：Windows | Mac | Linux 官方介绍：（见过最详[冗]细[长]的介绍了）Compare files and folders using simple, powerful commands that focus on the differences you’re interested in and ignore those you’re not. Merge changes, synchronize files, and generate reports.Beyond Compare中文版是一款专业的文本文件对比工具，可以高效的针对文件、文件夹、表格、mp3、图片、数据、注册表等文件并进行比较、合并、同步分析，并把相差的每一个字节用颜色加以表示，查看方便。非官方介绍：灰常强大的对比工具 中文官网下载时候需要填写个人信息，不想泄露个人信息的话，可以从英文官网下载，下载地址为：https://www.scootersoftware.com/download.php 使用场景：这俩文件（夹）有啥区别嘞？ 文本编辑器Vim主页：https://www.vim.org/ 适用系统：Windows | Mac | Linux 官方介绍：the ubiquitous text editor非官方介绍：程序猿中普及的诡异而又高效的编辑器 使用场景：换个思维方式来编辑文本 Notepad2主页：http://www.flos-freeware.ch/ 网友修改增强版地址：https://xhmikosr.github.io/notepad2-mod/ 适用系统：Windows 官方介绍：Utilities and Source Codes for Windows非官方介绍：小巧，实用，漂亮的文本编辑器 使用场景：想要替换Windows显得简陋的记事本（notepad.exe）工具 Visual Studio Code主页：https://code.visualstudio.com/ 适用系统：Windows | Mac | Linux 官方介绍：Code editing. Redefined.非官方介绍：微软出品的跨平台的优质代码编辑器 使用场景：web开发利器，不想打开IDE时一个轻量级代码阅读编辑工具 Sublime Text主页：https://www.sublimetext.com/ 适用系统：Windows | Mac | Linux 官方介绍：A sophisticated text editor for code, markup and prose非官方介绍：帅气、高效、跨平台的编辑器 使用场景：看我写代码工具帅不帅 Atom主页：https://atom.io/ 适用系统：Windows | Mac | Linux 官方介绍：A hackable text editor for the 21st Century非官方介绍：高颜值但是用起来卡卡卡的编辑器 使用场景：别给我说其他的啥啥功能强大，颜即正义，我就稀饭阿童木 Typora主页：https://www.typora.io/ 适用系统：Windows | Mac | Linux 官方介绍：Typora — a markdown editor, markdown reader.非官方介绍：高颜值所见即所得的markdown编辑器 使用场景：两个栏写markdown太复杂了，编辑直接看 设计Enterprise Architect主页：http://sparxsystems.com/products/ea/index.html 适用系统：Windows 官方介绍：UML Design Tools and UML CASE tools for software development非官方介绍：专业的UML设计软件 使用场景：是时候找个强大专业的工具来设计下我的工程了 Visio主页：https://products.office.com/en-US/visio 适用系统：Windows | Mac 官方介绍：Flowchart Maker &amp; Diagramming Software非官方介绍：Office绘制UML小帮手 使用场景：画个漂亮的流程图 远程工具OpenSSH主页：https://www.openssh.com/ 适用系统：Windows | Mac | Linux 官方介绍：OpenSSH is the premier connectivity tool for remote login with the SSH protocol非官方介绍：原始好用的SSH工具Mac, Linux上自带，Windows10之后也提供了可选安装的OpenSSH客户端 使用场景：快！我要连上那个服务器！ MobaXterm主页：https://mobaxterm.mobatek.net/ 适用系统：Windows 官方介绍：MobaXterm free Xserver and tabbed SSH client for Windows非官方介绍：Windows上简单、免费、好用、功能强大的远程工具，除了SSH还支持远程Windows哦。另外MobaXterm的分屏同时输入功能很好用。 使用场景：换个赏心悦目的远程工具吧 PuTTY主页：https://www.putty.org/ 适用系统：Windows 官方介绍：a free SSH and telnet client for Windows非官方介绍：小巧的SSH客户端Windows10上安装了系统自带的SSH客户端后，我觉得PuTTY作用已经不是很大了。如果说小巧，Windows10自带的ssh客户端才是真小巧，如果论功能，远不及MobaXterm和Xshell另外PyTTY有很多网友改装版，在此就不列举了，大家可以自己搜搜 使用场景：我不嫌丑，就想来个轻便而不简陋的SSH客户端 Xshell主页：https://www.netsarang.com/products/xsh_overview.html 适用系统：Windows 官方介绍：The Industry’s Most Powerful SSH Client非官方介绍：是个不错的ssh客户端，但是官方介绍口气大的不行不行的。使用此工具时请注意版权！用于商业时请尊重版权。我工作过有两家大公司都因为版权问题禁止使用。 使用场景：换个666的SSH客户端 数据库Robomongo主页：https://robomongo.org/ 适用系统：Windows | Mac | Linux 官方介绍：native MongoDB management tool (Admin UI)非官方介绍：好用的MongoDB管理工具，支持界面化查看数据，支持使用mongo命令查询数据以前叫做Robomongo，后来改名为Robo 3T，另外现在还有更专业的Studio 3T 使用场景：来个轻便好用的MongoDB开发者工具 MongoDB Compass主页：https://www.mongodb.com/products/compass 适用系统：Windows | Mac | Linux 官方介绍：The easiest way to explore and manipulate your MongoDB data非官方介绍：这是官方的MongoDB管理工具，好用哦 使用场景：官方工具闪亮登场 DBeaver主页：https://dbeaver.com/ 适用系统：Windows | Mac | Linux 官方介绍：Universal Database Manager非官方介绍：多种数据库的管理好工具此工具分免费的社区版（DBeaver CE）和收费的企业版（DBeaver EE） 使用场景：来个跨平台支持各种数据库的管理工具]]></content>
      <tags>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyCharm远程调试Python代码]]></title>
    <url>%2Fdoc%2Fpython%2Fpycharm-remote-debug%2F</url>
    <content type="text"><![CDATA[简介本文将介绍如何使用PyCharm进行远程调试Python代码。 准备 PyCharm 远程环境，本例中为linux系统 方法一：使用远程解释器调试 准备代码以下为需要远程调试的代码demo.py 1234567891011121314#!/usr/bin/python# -*- coding:utf-8 -*-import socketdef hello_world(name="world!"): print("hello " + name) hostname = socket.gethostname() print(hostname)if __name__ == "__main__": hello_world() PyCharm连接到远程环境点击【Tools】-【Deployment】-【Configuration】 点“+”加号，新增一个sftp配置 填写host, port, User name, Password等信息，填写好后可以点击Test SFTP connection...来测试配置是否正确。可以点击Autodetect自动填写Root path，或者手动配置 点击【Mappings】来配置远程服务器目录和本地目录映射关系，填写Local path, Deployment path on server，也可以点击右侧...来手动选择目录。注意，Deployment path on server填写的是以Root path为根目录的相对路径，可以在【Excluded Paths】中填写需要被排除同步的文件或文件夹，点击OK保存配置 上传代码至远程服务器在需要上传的代码或文件夹上点击右键-【Deployment】-【Upload to …】，即可将代码上传至远程服务器 可以点击【Tools】-【Deployment】-【Browse Remote Host】查看远程服务器Root path下的目录结构 配置远程解释器点击【settings】-【Project Interpreter】-【右上方小齿轮】-【add】 点击【SSH Interpreter】-【Existing server configuration】，然后选择move，下一步 填写Interpreter（远程服务器Python解释器路径）,以及Sync folders（本地目录和远程目录的映射关系），点击Finish完成 开始调试或运行在保证远程Python解释器环境安装了工程所需的依赖包后，开始调试或者运行即可 方法二：使用pycharm-debug包调试 准备代码以下为需要远程调试的代码demo.py，将代码上传至远程服务器上 1234567891011121314#!/usr/bin/python# -*- coding:utf-8 -*-import socketdef hello_world(name="world!"): print("hello " + name) hostname = socket.gethostname() print(socket.gethostname())if __name__ == "__main__": hello_world() 远程服务器上安装pytharm-debug.egg（Python2.x适用）或pycharm-debug-py3k.egg（Python3.x适用）安装包位于pycharm安装目中的debug-eggs目录中，将需要的安装包上传至远程服务器上，使用如下命令安装依赖包： 1easy_install pycharm-debug.egg 在本地pycharm中新建远程调试配置 新建Python Remote Debug 填写本地ip，端口（本地启动调试服务的端口，不和已有端口冲突即可），远程和本地目录映射关系（此处可以不配置，调试启动是选择Download远程代码也可以） 修改远程需要调试的代码 将如下代码添加至远程需要被调试的代码中，添加至需要开始调试的地方 12import pydevdpydevd.settrace('10.60.84.78', port=6666, stdoutToServer=True, stderrToServer=True) 例如： 1234567891011121314151617#!/usr/bin/python# -*- coding:utf-8 -*-import socketimport pydevddef hello_world(name="world!"): print("hello " + name) pydevd.settrace('10.60.84.78', port=6666, stdoutToServer=True, stderrToServer=True) hostname = socket.gethostname() print(hostname)if __name__ == "__main__": hello_world() 远程代码启动 1python demo.py 启动后，运行至pydevd.settrace(...处会等待pycharm启动debug PyCharm启动Remote Debug 此时若没有配置目录映射，则会提示如下信息： 选择Download可以下载远程代码，也可以配置目录映射 之后可进入到开始调试了的入口，可以开始调试啦]]></content>
      <tags>
        <tag>Python</tag>
        <tag>debug</tag>
        <tag>PyCharm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop分布式部署]]></title>
    <url>%2Fdoc%2Fhadoop%2Fhadoop-deploy%2F</url>
    <content type="text"><![CDATA[简介本文将介绍分布式部署hadoop方式，各角色部署使用独立的用户 HDFS 部署 httpfs 部署 yarn 部署 hive 部署 HBase 部署 环境准备 CentOS-7(Ubuntu亦可，或使用docker容器部署) hadoop-2.6.5.tar.gz zookeeper-3.4.12.tar.gz 计划 hostname 作用 node1 namenode, datanode, JournalNode, zookeeper node2 namenode, datanode, JournalNode, zookeeper node3 datanode, JournalNode, zookeeper, httpfs 安装步骤配置zookeeper12345678910111213141516171819# 添加zookeeper用户useradd zookeeper# 解压并安装zookeeper包tar -xvf zookeeper-3.4.12.tar.gzmv zookeeper-3.4.12 /opt/chown root:root /opt/zookeeper-3.4.12/ -Rln -vs /opt/zookeeper-3.4.12/ /opt/zookeeper# 创建配置文件cp /opt/zookeeper/conf/zoo_sample.cfg /opt/zookeeper/conf/zoo.cfg# 创建日志和数据目录mkdir /var/log/zookeeperchown zookeeper:zookeeper /var/log/zookeeper/mkdir /var/lib/zookeeperchown zookeeper:zookeeper /var/lib/zookeeper/ 在node1上执行：echo 1 &gt; /var/lib/zookeeper/myid在node2上执行：echo 2 &gt; /var/lib/zookeeper/myid在node3上执行：echo 3 &gt; /var/lib/zookeeper/myid 执行vim /opt/zookeeper/conf/zoo.cfg 底部添加如下内容1234dataDir=/var/lib/zookeeperserver.1=node1:2888:3888server.2=node2:2888:3888server.3=node3:2888:3888 执行vim /opt/zookeeper/bin/zkEnv.sh 修改如下内容1234if [ "x$&#123;ZOO_LOG_DIR&#125;" = "x" ]then ZOO_LOG_DIR="/var/log/zookeeper"fi 在node1, node2, node3上启动zookeeper1234# 启动su zookeeper -c "/opt/zookeeper/bin/zkServer.sh start"# 停止su zookeeper -c "/opt/zookeeper/bin/zkServer.sh stop" SSH 配置1234567891011121314151617181920# 创建用户组hadoopgroupadd hadoop# 创建用户hdfs并设置用户组为hadoopuseradd hdfs -g hadoop# 设置hdfs密码passwd hdfssu hdfs# 一路回车ssh-keygen# 将本主机的公钥分发至node1ssh-copy-id node1# 使用ssh-copy-id将：# node1, node2的公钥分发至node1, node2, node3# node3的公钥分发至node3 配置HDFS切换至root用户 安装和配置 1234567891011121314# 解压hadoop安装包tar -xvf hadoop-2.6.5.tar.gzmv hadoop-2.6.5 /opt/chown root:root /opt/hadoop-2.6.5 -Rln -vs /opt/hadoop-2.6.5/ /opt/hadoopmkdir /var/log/hadoop-hdfschown hdfs:hadoop /var/log/hadoop-hdfsmkdir /var/lib/hadoop-hdfschown hdfs:hadoop /var/lib/hadoop-hdfs 以下修改hdfs相关配置，配置文件位于目录/opt/hadoop/ect/hadoop 执行vim hadoop-env.sh 修改如下对应配置 123export HADOOP_LOG_DIR=/var/log/hadoop-hdfs# 此处注意修改为环境中对应的JAVA_HOME路径export JAVA_HOME=/usr/java/jdk1.8.0_171 执行vim core-site.xml，其中&lt;configuration&gt;节点修改为如下内容 123456789101112131415161718&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/var/lib/hadoop-hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://mycluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node1:2181,node2:2181,node3:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 执行vim hdfs-site.xml，其中&lt;configuration&gt;节点修改为如下内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;mycluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt; &lt;value&gt;node1,node2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.node1&lt;/name&gt; &lt;value&gt;node1:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.node1&lt;/name&gt; &lt;value&gt;node1:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.node2&lt;/name&gt; &lt;value&gt;node2:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.node2&lt;/name&gt; &lt;value&gt;node2:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://node1:8485;node2:8485;node3:8485/journal&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/var/lib/hadoop-hdfs&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt; sshfence shell(/bin/true) &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt; &lt;value&gt;30000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/var/lib/hadoop-hdfs/nn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/var/lib/hadoop-hdfs/dn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 执行vim slaves 替换为如下内容 123node1node2node3 执行cp mapred-site.xml.template mapred-site.xml 复制mapred-site.xml.template为mapred-site.xml执行vim mapred-site.xml，其中&lt;configuration&gt;节点修改为如下内容12345678&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动journalnode123su hdfs -c &quot;/opt/hadoop/sbin/hadoop-daemon.sh start journalnode&quot;# 对应停止命令如下# su hdfs -c &quot;/opt/hadoop/sbin/hadoop-daemon.sh stop journalnode&quot; 使用jps可以查到JournalNode进程如果无法使用jps则需要先导入java环境变量，例如使用source /etc/profile 初始化namenode 12345# node1上执行su hdfs -c &quot;/opt/hadoop/bin/hdfs namenode -format&quot;su hdfs -c &quot;scp -r /var/lib/hadoop-hdfs/nn hdfs@node2:/var/lib/hadoop-hdfs&quot;su hdfs -c &quot;/opt/hadoop/bin/hdfs zkfc -formatZK&quot;su hdfs -c &quot;/opt/hadoop/sbin/start-dfs.sh&quot; 打开http://node1:50070或http://node2:50070查看hdfs信息 配置HttpFs123456789101112# 创建用户useradd httpfs# 创建目录mkdir /var/log/hadoop-httpfschown httpfs:httpfs /var/log/hadoop-httpfs/mkdir /var/tmp/hadoop-httpfschown httpfs:httpfs /var/tmp/hadoop-httpfs/# 设置权限chmod +r /opt/hadoop/share/hadoop/httpfs/tomcat/conf -R vim httpfs-site.xml 12345678910111213&lt;configuration&gt; &lt;property&gt; &lt;name&gt;httpfs.proxyuser.hue.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;httpfs.proxyuser.hue.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vim core-site.xml 添加 123456789&lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.httpfs.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt; vim httpfs-env.sh 12export HTTPFS_LOG=/var/log/hadoop-httpfsexport HTTPFS_TEMP=/var/tmp/hadoop-httpfs 启动或停止 12su httpfs -c "/opt/hadoop/sbin/httpfs.sh start"su httpfs -c "/opt/hadoop/sbin/httpfs.sh stop" 附以下为本文档中所使用的docker容器构建和编排相关的文档，如果需要使用容器部署hadoop，可以参考使用 Dockerfile构建centos7-base镜像所使用的相关文件如下 目录结构123├── Dockerfile└── files └── jdk-8u171-linux-x64.tar.gz jdk下载地址：jdk-8u171-linux-x64.tar.gz Dockerfile内容12345678910111213141516171819FROM centos:7.2.1511MAINTAINER yancaiENV TZ Asia/Shanghai# 设置yum源 安装常用工具RUN curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo \ &amp;&amp; yum makecache \ &amp;&amp; yum install -y vim mlocate telnet zlib-devel openssh-server openssh-clients net-tools \ &amp;&amp; mkdir /usr/javaWORKDIR /root# 安装jdkADD files/jdk-8u171-linux-x64.tar.gz /usr/javaRUN echo "export JAVA_HOME=/usr/java/jdk1.8.0_171" &gt;&gt; /etc/profile \ &amp;&amp; echo "export PATH=\$JAVA_HOME/bin:\$PATH" &gt;&gt; /etc/profile \ &amp;&amp; echo "export CLASSPATH=.:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jar" &gt;&gt; /etc/profile \ &amp;&amp; ln -vs /usr/java/jdk1.8.0_171/bin/java /usr/bin/java 在Dockerfile所在目录使用sudo docker build --tag=&quot;centos7-base&quot; .构建镜像 docker-compose.yml以下为docker-compose.yml内容：12345678910111213141516171819202122232425262728293031version: '2.2'services: node1: image: centos7-base container_name: node1 hostname: node1 environment: - TZ=Asia/Shanghai command: tail -f /dev/null volumes: - ~/share:/root/share node2: image: centos7-base container_name: node2 hostname: node2 environment: - TZ=Asia/Shanghai command: tail -f /dev/null volumes: - ~/share:/root/share node3: image: centos7-base container_name: node3 hostname: node3 environment: - TZ=Asia/Shanghai command: tail -f /dev/null volumes: - ~/share:/root/share 在docker-compose.yml所在目录使用命令sudo docker-compose up -d启动容器 使用docker容器部署时，需要开启SSH服务，手动开启方式如下：123# 在容器内执行ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key/usr/sbin/sshd]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用docker-compose编排容器快速上手指南]]></title>
    <url>%2Fdoc%2Fdocker%2Fdocker-compose-quickstart%2F</url>
    <content type="text"><![CDATA[简介在了解了docker的基本用法以及使用dockerfile构建镜像后，我们可以看起来开森愉快的捣腾docker容器了。部署个nginx，折腾个tomcat，多版本Python，整个Hadoop等等等等。爽了一段时间，容器逐渐越来越多时候，就会发现又有了新问题。比个如，如果要搭建个简单的web服务，使用MySQL数据库（一个容器），使用Python Flask开发web（又一个容器），使用Nginx + uwsgi做反向代理（再一个容器），数据库可能会做读写分离，web服务可能会做高可用或者负载均衡。对于这个常见的场景，最简单那就几个容器一个个启动，彼此间约定好访问的ip或者域名。使用久了就会发现比较麻烦，如果要删除重新拉起一套，一个个查容器id，停止，删除，再启动，容器多了就会超级麻烦。 一个好的办法就是用docker-compose来管理编排多个服务。 本文将简单介绍使用docker-compose编排服务的基本使用方法。 docker-compose安装《Install Docker Compose》这个里面有关docker-compose的安装方法写的挺详细的，建议时间充足阅读这个。 这里简单介绍下快速安装docker-compose的方法。执行如下命令12345# 下载docker-composesudo curl -L https://github.com/docker/compose/releases/download/1.21.0/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose# 添加可执行权限sudo chmod +x /usr/local/bin/docker-compose 验证是否安装成功，输入如下命令，查看docker-compose版本 1$ sudo docker-compose --version 输出版本信息1docker-compose version 1.21.0, build 5920eb0 docker-compose使用方法demo示例下面展示个简单的例子，直接上相关文件内容： 创建一个demo的目录，目录中包含有docker-compose.yml的文件，目录结构如下：12demo└── docker-compose.yml docker-compose.yml中的内容如下：1234567891011121314151617181920212223242526272829303132333435363738version: '2.2'services: nginx: image: nginx:1.13.12 container_name: nginx hostname: nginx environment: - TZ=Asia/Shanghai ports: - 8000:8000 networks: - front command: tail -f /dev/null python: image: python:2.7 container_name: python hostname: python environment: - TZ=Asia/Shanghai networks: - front - backend command: tail -f /dev/null mysql: image: mysql:5.6 container_name: mysql hostname: mysql environment: - TZ=Asia/Shanghai networks: - backend command: tail -f /dev/nullnetworks: front: backend: 先解释下如上的内容： 创建了三个容器，分别为nginx, python, mysql； 创建了两个网络层面，分别为front和backend； nginx和python使用网络平面front，python和mysql使用网络平面backend，nginx无法访问mysql； 启动和验证进入demo目录，使用如下命令拉起容器：1sudo docker-compose up -d 看到如下内容说明拉起成功12345Creating network &quot;demo_front&quot; with the default driverCreating network &quot;demo_backend&quot; with the default driverCreating python ... doneCreating mysql ... doneCreating nginx ... done 使用命令sudo docker network ls，可以查到有名为demo_front和demo_backend的两个网路。使用命令sudo docker inspect demo_front或sudo docker inspect demo_backend可以查看网络平面详细信息。 使用命令sudo docker exec -it python /bin/bash，进入容器python。在容器python中测试访问nginx和mysql12ping nginxping mysql 容器python可以ping通容器nginx和容器mysql。 而nginx和mysql之间无法ping通。 停止和删除使用如下命令可以一把停止和删除相关容器和网络，而无需手动一个个的停止再删除1sudo docker-compose down 网路问题常见的一个问题：假如需要扩容或者增加一个python的web服务，不妨称之为webapp02，新的webapp02服务需要加入到上面的front网络平面中，需要和nginx以及上面的python服务相互访问。可以使用docker命令的--link把webapp02和nginx、python连接起来，更好的办法是使用docker-compose来编排新的webapp02和其它容器或者网络之间的关系。 示例如下：目录结构12demo-ext└── docker-compose.yml docker-compose.yml内容如下：1234567891011121314151617181920version: '2.2'services: webapp02: image: python:2.7 container_name: webapp02 hostname: webapp02 networks: - front # - backend environment: - TZ=Asia/Shanghai command: tail -f /dev/nullnetworks: front: external: name: demo_front# backend:# external:# name: demo_backend 进入demo-ext目录中使用命令启动1sudo docker-compose up -d 可以看到如下信息12WARNING: Some networks were defined but are not used by any service: backendCreating webapp02 ... done 进入容器webapp02后，测试可以ping通容器nginx和容器python，而无法ping通容器mysql。如需访问容器mysql删掉上面的#取消注释，重新使用命令sudo docker-compose up -d拉起即可。 以上为一个简单的docker-compose使用示例，后面将会给出一个详细的nginx+flask+mysql的示例。]]></content>
      <tags>
        <tag>docker</tag>
        <tag>docker-compose</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node.js安装配置]]></title>
    <url>%2Fdoc%2Fnodejs%2Fnodejs-install%2F</url>
    <content type="text"><![CDATA[简介本文简介Node.js的安装和npm, yarn的安装与代理配置方法。 安装包准备下载Node.js安装包: node-v8.11.1-linux-x64.tar.xz 安装配置Node.js解压并创建软连接12345# 解压至opt目录tar -xvf node-v8.11.1-linux-x64.tar.xz -C /opt# 建立软连接ln -vs /opt/node-v8.11.1-linux-x64 /opt/node 将node.js目录添加至环境变量在~/.zshrc或~/.bashrc中添加如下内容12export NODE_HOME=/opt/nodeexport PATH=$PATH:$NODE_HOME/bin 使用source ~/.zshrc或source ~/.bashrc导入环境变量输入node -v查看版本可以看到版本信息12&gt; node -vv8.11.1 配置cnpm使用淘宝的npm（TAONPM）镜像下载包时候很快 在~/.zshrc或~/.bashrc中添加如下内容1alias cnpm=&quot;npm --registry=https://registry.npm.taobao.org --cache=$HOME/.npm/.cache/cnpm --disturl=https://npm.taobao.org/dist --userconfig=$HOME/.cnpmrc&quot; 使用source ~/.zshrc或source ~/.bashrc导入环境变量，即可使用cnpm命令，用法和npm一致，安装包时候下载会从淘宝镜像下载，速度杠杠的！ 安装与配置yarn这里说的yarn是facebook推出的Node.js包管理工具yarn，和Hadoop家族中的Hadoop YARN是不一样的东西。yarn的包安装速度比npm快不少。 使用cnpm安装yarn1cnpm install yarn -g 将yarn目录添加至环境变量在~/.zshrc或~/.bashrc中添加如下内容1export PATH=$PATH:$HOME/.yarn/bin 使用source ~/.zshrc或source ~/.bashrc导入环境变量，即可使用yarn命令。 yarn可以使用上面提到的淘宝的npm镜像，这样yarn就更快了，配置yarn镜像方法很简单，使用命令1yarn config set registry https://registry.npm.taobao.org 或者在~/.yarnrc中添加：1registry &quot;https://registry.npm.taobao.org&quot; 之后即可使用yarn来安装管理包啦 npm与yarn常用配置命令1234567891011npm config set prefix D:\AppData\npmnpm config set cache D:\AppData\npm-cache# 设置镜像源npm config set registry http://registry.npm.taobao.org/yarn config set global-folder D:\AppData\yarn\globalyarn config set cache-folder D:\AppData\yarn\cache# 设置镜像源yarn config set registry https://registry.npm.taobao.org 快速链接 Node.js yarn]]></content>
      <tags>
        <tag>Node.js</tag>
        <tag>npm</tag>
        <tag>Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用dockerfile构建docker镜像快速上手指南]]></title>
    <url>%2Fdoc%2Fdocker%2Fdockerfile-quickstart%2F</url>
    <content type="text"><![CDATA[简介在了解了docker的基本使用方法后，我们可以通过容器快速准备环境并部署服务。有些重复性的工作，例如：手动配置一些配置项，安装特定的软件包，使用命令或脚本启动特定服务等等。为了解决这些通用或者重复性的事情，我们可以通过构建一个自己个性化的镜像来固化下来这些环境信息。 本文将简单介绍使用dockerfile构建docker镜像的基本使用方法。本文以使用ubuntu的镜像为例说明如何根据已有的镜像为基础构建自己需要的镜像。 本例中将演示以Ubuntu 16.04为基础，安装ssh, jdk, vim等软件。 安装包准备 jdk-8u77-linux-x64.tar.gz 目录结构及Dockerfile假如工作目录在：~/dockerfiles/my-ubuntu此目录中的结构如下： 123|-- Dockerfile`-- files `-- jdk-8u77-linux-x64.tar.gz 其中Dockerfile中的内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142FROM ubuntu:16.04LABEL maintainer="yancai915@gmail.com"ENV LANG zh_CN.UTF-8ENV LC_ALL zh_CN.UTF-8ENV TZ Asia/Shanghai# 设置apt-get源RUN sed -i "s/archive.ubuntu.com/mirrors.aliyun.com/g" /etc/apt/sources.list \ &amp;&amp; sed -i "s/security.ubuntu.com/mirrors.aliyun.com/g" /etc/apt/sources.list \ &amp;&amp; apt-get update# 安装常用工具 设置SSHRUN apt-get install -y openssh-server vim telnet sudo \ &amp;&amp; rm /etc/ssh/ssh_host_dsa_key -rf \ &amp;&amp; rm /etc/ssh/ssh_host_rsa_key -rf \ &amp;&amp; ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key \ &amp;&amp; ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key \ &amp;&amp; useradd guest \ &amp;&amp; echo "guest:guest!@#" | chpasswd \ &amp;&amp; echo "guest ALL=(ALL) ALL" &gt;&gt; /etc/sudoers \ &amp;&amp; echo "root:123456" | chpasswd \ &amp;&amp; sed -i "s/PermitRootLogin\ without-password/PermitRootLogin\ yes/g" /etc/ssh/sshd_config# 修改vim配置RUN sed -i '1s/^/set encoding=utf-8\n/' /etc/vim/vimrc \ &amp;&amp; echo "set hls" &gt;&gt; /etc/vim/vimrc \ &amp;&amp; echo "set expandtab" &gt;&gt; /etc/vim/vimrc \ &amp;&amp; echo "set sw=4" &gt;&gt; /etc/vim/vimrc \ &amp;&amp; echo "set tabstop=4" &gt;&gt; /etc/vim/vimrcRUN mkdir /usr/java# 安装jdkADD files/jdk-8u77-linux-x64.tar.gz /usr/javaRUN echo "export JAVA_HOME=/usr/java/jdk1.8.0_77" &gt;&gt; /etc/profile \ &amp;&amp; echo "export PATH=\$JAVA_HOME/bin:\$PATH" &gt;&gt; /etc/profile \ &amp;&amp; echo "export CLASSPATH=.:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jar" &gt;&gt; /etc/profileRUN mkdir /var/run/sshdEXPOSE 22 8080ENTRYPOINT /usr/sbin/sshd -D 构建镜像1234cd ~/dockerfiles/my-ubuntu# build镜像，注意最后有一个英文半角点号docker build --tag="my-ubuntu:1.0" . 稍等片刻后构建完成 查询镜像使用如下命令可以看到已经构建好的镜像1docker images 例如：12REPOSITORY TAG IMAGE ID CREATED SIZEmy-ubuntu 1.0 1979d1447f6d 2 minutes ago 612 MB]]></content>
      <tags>
        <tag>docker</tag>
        <tag>dockerfile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker快速上手指南]]></title>
    <url>%2Fdoc%2Fdocker%2Fdocker-quickstart%2F</url>
    <content type="text"><![CDATA[本文将简单介绍docker的基本使用方法。本文以使用nginx的镜像为例说明如何快速上手使用docker。 docker 安装参见: https://docs.docker.com/install/ 拉取镜像1docker pull nginx 启动容器12# 启动一个nginx容器，主机的8000转发至容器的80端口docker run -d --name my-nginx -p 8000:80 nginx 测试访问nginx浏览器访问http://{主机ip}:8000，可以看到Welcome to nginx!页面 停止容器12# 查询已经启动的容器docker ps 例如查到类似如下信息： 12CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb8eca8f07f68 nginx &quot;nginx -g &apos;daemon ...&quot; 24 seconds ago Up 23 seconds 0.0.0.0:8000-&gt;80/tcp my-nginx 12# 使用my-nginx对应的ContainerID停止容器docker stop &#123;container_id&#125; 删除容器12# 使用my-nginx对应的ContainerID删除容器docker rm &#123;container_id&#125; 注意 如果容器已经停止，可以使用命令docker ps -a查询所有包含已停止的容器;]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flume和kafka单节点部署和使用的方法]]></title>
    <url>%2Fdoc%2Fhadoop%2Fflume_kafka_single%2F</url>
    <content type="text"><![CDATA[flume kafka single本文介绍了flume和kafka单节点部署和使用的方法 安装包准备 kafka: kafka_2.11-1.0.0.tgz flume: apache-flume-1.8.0-bin.tar.gz kafka部署配置 解压kafka安装包至指定目录/opt/kafka 启动zookeeper（也可单独部署zookeeper） 1./bin/zookeeper-server-start.sh -daemon ./config/zookeeper.properties 启动成功后可以查询2181端口已确认是否启动成功 启动 kafka 1./bin/kafka-server-start.sh -daemon ./config/server.properties 启动成功后可以查询9092端口已确认是否启动成功 flume部署配置 解压flume安装包至指定目录/opt/flume 修改flume配置文件./conf/flume-conf.properties 12345678910111213141516171819a1.sources = r1a1.sinks = k1a1.channels = c1a1.sources.r1.type = netcata1.sources.r1.bind = 0.0.0.0a1.sources.r1.port = 44444a1.sources.r1.channels = c1a1.channels.c1.type = filea1.channels.c1.checkpointDir = /var/log/flume/checkpointa1.channels.c1.dataDirs = /var/log/flume/dataa1.sinks.k1.channel = c1a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSinka1.sinks.k1.brokerList=localhost:9092a1.sinks.k1.batchSize=10a1.sinks.k1.topic=flume-topica1.sinks.k1.request.required.acks=1 启动flume 1./bin/flume-ng agent --conf conf --conf-file conf/flume-conf.properties --name a1 -Dflume.root.logger=WARN,console 使用jps或者ps查询flume进程是否启动成功 测试flume到kafka的消息传递 向flume发送消息 12&gt;telnet flume 44444&gt;输入任意字符 从kafka读取消费消息 1./bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic flume-topic --from-beginning kafka常用命令12# 查询各组消费状态./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group g2]]></content>
      <tags>
        <tag>FlumeNG</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter快速部署]]></title>
    <url>%2Fdoc%2Fpython%2Fdeploy_jupyter%2F</url>
    <content type="text"><![CDATA[简介本文简介如何部署jupyterjupyter类似web版的ipython，吊炸天，帅爆了，很适合写代码示例或者技术文档 部署步骤默认目录为：/home/jupyter 使用virtualenv创建虚拟环境virtualenv jupyter_env 进入虚拟环境linux：source env/bin/activewindows：jupyter_env\Scripts\activate 安装jupyterpip install jupyter 启动jupyterjupyter notebook --ip 0.0.0.0 --port 8000浏览器打开地址访问jupyter：http://ip:port]]></content>
      <tags>
        <tag>Python</tag>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式 HA HDFS YARN SPARK HBASE部署]]></title>
    <url>%2Fdoc%2Fhadoop%2Fhadoop_ha_deploy%2F</url>
    <content type="text"><![CDATA[分布式 HA HDFS YARN SPARK HBASE部署本文介绍了支持HA方式的HDFS + YARN + HBase + Spark的部署方式 部署计划机器环境操作系统：CentOS-7 默认在/root中执行操作如果对网络端口设置不熟悉，请先关闭防火墙 12345# 停止firewallsystemctl stop firewalld.service# 禁止firewall开机启动systemctl disable firewalld.service 机器划分 hostname 包含角色 nd1（主） namenode, datanode, resourcemanager, nodemanager, zookeeper, hmaster, hregionserver nd2（主） namenode, datanode, resourcemanager, nodemanager, zookeeper, hmaster, hregionserver nd3 datanode, nodemanager, zookeeper, hregionserver 安装包准备 jdk-7u75-linux-x64.rpm hadoop-2.6.4.tar.gz zookeeper-3.4.8.tar.gz hbase-0.98.18-hadoop2-bin.tar.gz spark-1.6.1-bin-hadoop2.6.tgz 基础环境配置配置hostname及hosts选三台机器，按照部署计划配置hosts和hostname 配置ssh登录 生成ssh远程登录公钥-密钥对 ssh-keygen -t rsa 连续回车enter确认 由于nd1和nd2为master角色，因此nd1和nd2需要可以访问所有主机，将nd1和nd2的公钥分发给所有机器 如果nd1希望可以ssh无密钥访问nd2，那么需要将nd1自己的~/.ssh/id_rsa.pub中的公钥添加至nd2的~/.ssh/authorized_keys中。ssh提供了ssh-copy-id来简化复制粘贴的操作。 例如在nd1上执行： 12345678# 将nd1的公钥分发给nd1，如有提示，输入yes确认，输入nd1登录密码传输公钥ssh-copy-id nd1# 将nd1的公钥分发给nd2，如有提示，输入yes确认，输入nd2登录密码传输公钥ssh-copy-id nd2# 将nd1的公钥分发给nd3，如有提示，输入yes确认，输入nd3登录密码传输公钥ssh-copy-id nd3 在nd2上重复如上分发动作，将nd2的公钥分发给所有机器在nd3上，将nd3的公钥分发给nd3自己 在nd1上执行ssh-copy-id nd1以确保nd1可以ssh登录nd1自身；在nd1上执行ssh-copy-id nd2以确保nd2可以ssh登录nd2自身；在nd1上执行ssh-copy-id nd3以确保nd3可以ssh登录nd3自身； 验证ssh是否可远程至目标机器，使用ssh hostname验证是否可远程免密登录指定机器。在本例中，nd1和nd2可以远程登录nd1、nd2以及nd3。 安装配置Java 安装Java 1rpm -ivh jdk-7u75-linux-x64.rpm 配置环境变量打开/etc/profile，vim /etc/profile，最下方添加如下内容： 123export JAVA_HOME=/usr/java/jdk1.7.0_75export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 导入环境变量source /etc/profile，输入java -version测试Java是否配置成功，正常输出如下信息： 123java version &quot;1.7.0_75&quot;Java(TM) SE Runtime Environment (build 1.7.0_75-b13)Java HotSpot(TM) 64-Bit Server VM (build 24.75-b04, mixed mode) 部署zookeeper 解压并重命名 12345# 解压tar -xvf zookeeper-3.4.8.tar.gz# 重命名mv zookeeper-3.4.8 zookeeper 配置环境变量 打开/etc/profile并修改添加如下内容： 12export ZOOKEEPER_HOME=/root/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin 导入环境变量source /etc/profile 配置zookeeper 新建文件夹存储zookeeper文件mkdir /var/lib/zookeeper进入zookeeper程序目录，cd /root/zookeeper重命名配置文件mv conf/zoo_sample.cfg conf/zoo.cfg修改zoo.cfg，修改添加如下内容： 1234dataDir=/var/lib/zookeeperserver.1=nd1:2888:3888server.2=nd2:2888:3888server.3=nd3:2888:3888 在nd1上执行：echo 1 &gt; /var/lib/zookeeper/myid在nd2上执行：echo 2 &gt; /var/lib/zookeeper/myid在nd3上执行：echo 3 &gt; /var/lib/zookeeper/myid 启动并验证 启动方式：./bin/zkServer.sh start 验证方式：输入jps查询进程可以看到QuorumPeerMain，则说明zookeeper已启动。使用./bin/zkCli.sh进入zookeeper客户端命令行，并执行： 123input: ls /# 看到[zookeeper]即说明服务运行正常output: [zookeeper] 部署Hadoop(HDFS + YARN) 解压并重命名 123cd ~tar -xvf hadoop-2.6.4.tar.gzmv hadoop-2.6.4 hadoop 配置环境变量 打开vim /etc/profile并修改添加如下内容： 12export HADOOP_HOME=/root/hadoopexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 导入环境变量source /etc/profile 配置hadoop 新建文件夹存储hadoop文件mkdir /var/lib/hadoop进入hadoop程序目录，cd /root/hadoop 修改etc/hadoop/hadoop-env.sh 1export JAVA_HOME=/usr/java/jdk1.7.0_75 修改vim etc/hadoop/core-site.xml在&lt;configuration&gt;&lt;/configuration&gt;间添加如下内容： 123456789101112131415161718&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/var/lib/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://mycluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;nd1:2181,nd2:2181,nd3:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改vim etc/hadoop/hdfs-site.xml在&lt;configuration&gt;&lt;/configuration&gt;间添加如下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;mycluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt; &lt;value&gt;nd1,nd2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nd1&lt;/name&gt; &lt;value&gt;nd1:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nd1&lt;/name&gt; &lt;value&gt;nd1:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nd2&lt;/name&gt; &lt;value&gt;nd2:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nd2&lt;/name&gt; &lt;value&gt;nd2:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://nd1:8485;nd2:8485;nd3:8485/journal&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/val/lib/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt; sshfence shell(/bin/true) &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt; &lt;value&gt;30000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/var/lib/hadoop/nn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/var/lib/hadoop/dn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 复制mapred-site配置，cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml修改vim etc/hadoop/mapred-site.xml在&lt;configuration&gt;&lt;/configuration&gt;间添加如下内容： 12345678&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改vim etc/hadoop/yarn-site.xml在&lt;configuration&gt;&lt;/configuration&gt;间添加如下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;YARN-HA&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;nd1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;nd2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;nd1:2181,nd2:2181,nd2:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-service&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改vim etc/hadoop/slaves添加如下内容： 123nd1nd2nd3 格式化并启动服务 启动journalnode，在nd1，nd2，nd3上执行hadoop-daemon.sh start journalnode格式化namenode，在nd1上执行hdfs namenode -format，拷贝nd1的namenode的目录至nd2的相同目录中scp -r /var/lib/hadoop/nn root@nd2:/var/lib/hadoop/有类似如下信息输出则为正常： 12316/04/06 09:06:16 INFO common.Storage: Storage directory /var/lib/hadoop/nn has been successfully formatted.16/04/06 09:06:17 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 016/04/06 09:06:17 INFO util.ExitUtil: Exiting with status 0 ps1: 也可以在nd2上先执行格式化在拷贝目录至nd1ps2: 此处可使用网络共享磁盘方式使得nd1和nd2同时读写同一个目录，生产环境建议使用此方法 格式化zookeeper中的hadoop信息，在nd1或者nd2上执行hdfs zkfc -formatZK启动hdfs，在nd1或者nd2上执行start-dfs.sh，在nd1和nd2上使用jps查看会有如下进程： 12345JournalNodeQuorumPeerMainDFSZKFailoverControllerNameNodeDataNode 在nd3上执行jps查看会有如下进程： 123JournalNodeQuorumPeerMainDataNode 浏览器中打开http://nd1:50070和http://nd2:50070中可以看到其中一个为active，另一个为standby，则说明hadoop namenode的HA配置成功或者使用hdfs haadmin -getServiceState nd1来查询nd1的当前状态可以在active的机器上强制杀死namenode或者使用hadoop-daemon.sh stop namenode来模拟active namenode故障，之后刷新另一个节点的页面可以看到状态已经由standby变成了active由此可以验证hdfs的HA成功 启动yarn在nd1上执行start-yarn.sh，启动nd1的resourcemanager以及nd1-3的nodemanager再在nd2上执行yarn-daemon.sh start resourcemanager，启动nd2的resourcemanager使用jps查询进程可以在nd1和nd2上看到包含有进程：resourcemanager和nodemanager在nd3上可以看到包含有进程：nodemanager在浏览器打开http://nd1:8088可以看到yarn的applications界面，打开http://nd2:8088会自动跳转至nd1的界面或者使用yarn rmadmin -getServiceState rm1来查询rm1或rm2的状态在nd1上杀死resourcemanager的进程或者使用yarn-daemon.sh stop resourcemanager停止resourcemanager进程，这时访问http:nd2:8080，可以看到resourcemanager已经由nd2接替。或者使用yarn rmadmin -getServiceState xxx来查询每个resourcemanager的状态由此可以验证yarn的HA成功 部署HBase 解压并重命名 123cd ~tar -xvf hbase-0.98.18-hadoop2-bin.tar.gzmv hbase-0.98.18-hadoop2-bin hbase 配置环境变量 打开vim /etc/profile并修改添加如下内容： 12export HBASE_HOME=/root/hbaseexport PATH=$PATH:$HBASE_HOME/bin 导入环境变量source /etc/profile 配置HBase 新建文件夹存储HBase文件mkdir /var/lib/hbase进入hbase程序目录，cd /root/hbase 修改vim conf/hbase-env.sh，在最下放添加如下内容： 12export JAVA_HOME=/usr/java/jdk1.7.0_75/export HBASE_MANAGES_ZK=false 修改vim conf/hbase-site.xml在&lt;configuration&gt;&lt;/configuration&gt;间添加如下内容： 1234567891011121314151617181920212223242526272829303132333435363738&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://mycluster/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;nd1,nd2,nd3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/var/lib/zookeeper/&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master&lt;/name&gt; &lt;value&gt;60000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改vim conf/regionservers在文件中添加如下内容： 123nd1nd2nd3 将hadoop中的core-site.xml，hdfs-site.xml拷贝至hbase/conf/中或者使用软连接方式，推荐使用软连接方式： 123# 建立软连接ln -vs /root/hadoop/etc/hadoop/core-site.xml /root/hbase/conf/core-site.xmlln -vs /root/hadoop/etc/hadoop/hdfs-site.xml /root/hbase/conf/hdfs-site.xml 启动验证服务 在nd1上执行start-hbase.sh，在nd2上执行hbase-daemon.sh start master在nd1和nd2上使用jps查询可以看到 12HMasterHRegionServer 浏览器中打开http://nd1:60010或http://nd2:60010可以看到当前HMaster的状态 在状态为master的机器上执行hbase-daemon.sh stop master或者直接杀死HMaster进程，访问另一个节点对应的HBase web页面，则可看到状态已由Backup变为Master由此可验证HBase的HA切换成功 部署 Spark On YARN spark主要的部署方式有：YARN模式、Standalone模式、HA模式 由于已经部署了YARN HA，因此采用Spark On YARN时，spark仅作为提交作业的客户端，具体的map-reduce任务交由YARN去处理，因此仅需要在一台机器上部署spark即可。 解压并重命名 12345# 解压tar -xvf spark-1.6.1-bin-hadoop2.6.tgz# 重命名mv spark-1.6.1-bin-hadoop2.6 spark 配置环境变量 打开/etc/profile并修改添加如下内容： 12export SPARK_HOME=/root/zookeeperexport PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin 导入环境变量source /etc/profile 配置spark 进入spark程序目录，cd /root/spark复制spark-env.sh配置，cp conf/spark-env.sh.template conf/spark-env.sh修改vim conf/spark-env.sh，在最下放添加如下内容： 1HADOOP_CONF_DIR=/root/hadoop/etc/hadoop 测试提交作业 使用spark-submit提交作业，参数Master URL指定为yarn即可，例如： 1spark-submit --class com.xxx --master yarn xxx.jar]]></content>
      <tags>
        <tag>Hadoop</tag>
        <tag>Hadoop-YARN</tag>
        <tag>Spark</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人开发的博客介绍]]></title>
    <url>%2Fdoc%2Fmydev%2Fblog_readme%2F</url>
    <content type="text"><![CDATA[简介自我推荐一个自己开发的简易博客。https://github.com/yancai/blog 此博客是一个基于Flask和Python Markdown开发的简易博客。本博客支持基本的Markdown语法，并且支持table和Meta信息，具体参见About.md 工程依赖包安装本工程主要依赖于Flask、Jinja2，具体参见requirement.txt pip install -r requirements.txt 基本用法 Python环境搭建及依赖包安装，依赖包参见requirements.txt； 将你写好的.md文件丢到generate.py中INPUT_CONTENT所配置的目录中，默认为./in目录； 运行generate.py文件，生成html页面文件和索引文件； 运行blog.py文件，启动flask网站，用以对外提供访问html文件； 访问http://127.0.0.1:5000/api/index/generate/生成索引文件； 访问http://127.0.0.1:5000/upload/上传你编写好的md文件（md文件名请使用英文字母、数字、中划线、下划线的组合）； 工程结构简介blog ├─start.sh -- linux启动脚本 ├─stop.sh -- linux停止脚本 ├─start.bat -- windows启动脚本 ├─blog.py -- flask工程主文件 ├─generate.py -- Markdown生成html工具 ├─ReadMe.md -- 本文档 ├─requirements.txt -- 依赖包 ├─settings.py -- flask 配置 │ ├─api -- 数据查询接口 ├─in │ └─About.md -- 博客撰写方法说明 │ ├─static -- 静态资源文件夹 │ ├─favicon.ico │ ├─css │ ├─font │ ├─fonts │ └─js ├─templates -- html模板 └─utils -- 工具类 示例]]></content>
      <tags>
        <tag>blog</tag>
        <tag>Python</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
</search>
